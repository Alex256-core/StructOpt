# StructOpt (Experimental First-Order Optimizer)

StructOpt is an experimental first-order optimizer that uses a simple structural
signal based on gradient changes between steps.  
The goal of this prototype is to explore whether aspects of local loss surface
geometry can be partially recovered without Hessians or Hessian-vector products.

### Key Characteristics
- fully first-order  
- does not use second derivatives  
- computes a simple â€œlandscape changeâ€ indicator  
- adaptively mixes two update regimes  

This repository contains:
- a minimal working demo on the Rosenbrock function  
- plots illustrating optimizer behavior  
- a concise technical description (without theoretical details)

âš  **Note:** This is an early-stage research prototype.  
It is *not* a production optimizer and is intended only for experimentation.

---

## ğŸ”§ Core Idea

On each step, the optimizer measures changes in the gradient:

`S_t = ||g_t â€“ g_{t-1}|| / (||Î¸_t â€“ Î¸_{t-1}|| + Îµ)`

S_t acts as a crude stiffness indicator:

- **low S_t** â†’ flat region â†’ accelerate  
- **high S_t** â†’ sharp/unstable region â†’ stabilize  

Mixing weight:

`Î±_t = sigmoid(a0 + a1 * ((S_t â€“ S_ref) / (S_ref + Îµ)))`

Update step:

`Î”Î¸ = â€“Î· * ( Î±_t * d_t + (1 â€“ Î±_t) * g_t )`

where d_t is a simple diagonal normalization of the gradient.

---

## ğŸ“ Repository Contents

- `structopt_demo.py` â€“ minimal optimizer demo  
- `loss_curve.png` â€“ loss vs iterations  
- `signal_curve.png` â€“ structural signal S(t)  
- `trajectory.png` â€“ 2D trajectory on Rosenbrock  

---

## âš  Disclaimer
This project is provided solely for research and documentation purposes.  
It does not reveal any proprietary or sensitive theoretical details.
